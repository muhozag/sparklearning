{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOL1UBbE0r3xT4RpzUGgdIP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhozag/sparklearning/blob/logreg/logreg1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Example: Predicting Titanic Passenger Survival"
      ],
      "metadata": {
        "id": "HQ7pyzNSAZhM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XeMeDPsq6dOZ"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SparkSession = SparkSession.builder.appName('titanic').getOrCreate()"
      ],
      "metadata": {
        "id": "YJHl8DPp7Fbo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = SparkSession.read.csv('titanic.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "JQblifoH7UwK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACjuu1LK7izk",
        "outputId": "cd85e188-b483-4f6c-b831-d48f24bd0bae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_cols = df.select(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'])"
      ],
      "metadata": {
        "id": "fvZ4-dGB7wDq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_final_data = my_cols.na.drop()"
      ],
      "metadata": {
        "id": "ojHwwAar8KpM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import (VectorAssembler,\n",
        "                                VectorIndexer, OneHotEncoder, StringIndexer)"
      ],
      "metadata": {
        "id": "KhngLSFR8Xo-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_indexer = StringIndexer(inputCol='Sex', outputCol='SexIndex')\n",
        "gender_encoder = OneHotEncoder(inputCol='SexIndex', outputCol='SexVec')"
      ],
      "metadata": {
        "id": "2a-qCE6Y8eUh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embark_indexer = StringIndexer(inputCol='Embarked', outputCol='EmbarkIndex')\n",
        "embark_encoder = OneHotEncoder(inputCol='EmbarkIndex', outputCol='EmbarkVec')"
      ],
      "metadata": {
        "id": "kFgxpCg99tG4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=['Pclass', 'SexVec', 'Age', 'SibSp', 'Parch', 'Fare', 'EmbarkVec'],\n",
        "                           outputCol='features')"
      ],
      "metadata": {
        "id": "DbQk6FU391nN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline"
      ],
      "metadata": {
        "id": "ZdIFbxAv-DDO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg_titanic = LogisticRegression(featuresCol='features', labelCol='Survived')"
      ],
      "metadata": {
        "id": "xkSGi5WG-PcV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=[gender_indexer, embark_indexer, gender_encoder, embark_encoder,\n",
        "                            assembler, log_reg_titanic])"
      ],
      "metadata": {
        "id": "amjFvdLP-cV_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = my_final_data.randomSplit([0.8,0.2])"
      ],
      "metadata": {
        "id": "i2Tw4oKg-94V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_model = pipeline.fit(train_data)"
      ],
      "metadata": {
        "id": "mw9wELD2_SdG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = fit_model.transform(test_data)"
      ],
      "metadata": {
        "id": "VpNL5kqv_Z3j"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ],
      "metadata": {
        "id": "Nl8isEUS_dxg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Survived')"
      ],
      "metadata": {
        "id": "WN5eMXYO_iwX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUC = my_eval.evaluate(results)"
      ],
      "metadata": {
        "id": "c9HEvTyg_vAx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPLdRrE_AByq",
        "outputId": "f497fa3b-ee9b-45c2-aa6b-11741ff3a4f3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7664473684210528"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}